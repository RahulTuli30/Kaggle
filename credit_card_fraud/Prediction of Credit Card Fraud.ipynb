{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will train and cross-validate an algorithm to predict credit card fraud, with highest possible \"accuracy\". Due to the highly imbalanced nature of the data we need to be careful how to measure error. I will distinguish between two types of error: (a) percentage of frauds detected among non-fraudulent transactions (1st kind), and (b) percentage of frauds that are not recognized (2nd kind)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = pd.read_csv(\"data/creditcard.csv\")\n",
    "df_orig = df.copy(deep = True)        # keep a copy for cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have tried several algorithms, but Logistic Regression performed best (I cannot tell about SVC - I have tried it, but I had to abort it after many hours). Note the weight-option - this compensates for the imbalance of classes (i.e. fraud vs. non-fraud):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrn = LogisticRegression(penalty = 'l2', C= 1, class_weight='balanced' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will shuffle the data, split it into a training set (80%) and a test set (20%), train the algorithm on the training set, and then test it. I repeat this N times, in order to get a good measure of the quality of the classifier. For sake of clarity I define functions that I will loop over afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_sets():\n",
    "    df = df_orig.copy(deep = True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)        #shuffle\n",
    "    \n",
    "    y = df.Class.tolist()\n",
    "    df = df.drop('Class', 1)\n",
    "    X = df.as_matrix()\n",
    "    \n",
    "    # create test and training set\n",
    "    p = 0.2                      #fraction of test sample\n",
    "    X_test = X[:int(p*len(y))]\n",
    "    y_test = y[:int(p*len(y))]\n",
    "    X_train = X[int(p*len(y)):]\n",
    "    y_train = y[int(p*len(y)):]\n",
    "    return X_test, y_test, X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the algorithm and then testing it. For testing, we count the errors of first and second kind (see first paragraph):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test():\n",
    "    X_test, y_test, X_train, y_train = create_sets()\n",
    "    \n",
    "    lrn.fit(X_train, y_train)\n",
    "    \n",
    "    y_predict = lrn.predict(X_test)\n",
    "\n",
    "    # count the errors:\n",
    "    c_0 = 0\n",
    "    c_1 = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if (y_test[i] == 0) and (y_predict[i] == 1):\n",
    "            c_0 += 1\n",
    "        if (y_test[i] == 1) and (y_predict[i] == 0):\n",
    "            c_1 += 1\n",
    "\n",
    "    n_fraud = np.sum(y_test)\n",
    "    return (100*c_0)/(len(y_test)-n_fraud), (100*c_1)/(n_fraud)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run through train_test() many times in order to get good estimates for the errors (I have used this crossvalidation for different algorithms, as well in order to obtain the optimal C in the logistic regression):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of first kind  = 2.2%\n",
      "Error of second kind = 10.2%\n"
     ]
    }
   ],
   "source": [
    "N = 10        #number of iterations\n",
    "f_1 = 0      #counts the errors of the first kind (already in percent)\n",
    "f_2 = 0      #counts the errors of the second kind\n",
    "for n in range(N):\n",
    "    a, b = train_test()\n",
    "    f_1 += a\n",
    "    f_2 += b\n",
    "\n",
    "print(\"Error of first kind  = {}%\".format(((10*f_1)//N)/10))\n",
    "print(\"Error of second kind = {}%\".format(((10*f_2)//N)/10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not too bad - however, there is still room for improvement. One aspect might be to reduce the error of first kind - 2% false alarms for non-fraudulent transactions can be pretty annoying in practice."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
