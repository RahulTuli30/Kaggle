{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analyzing the patterns of total eclipses (i.e. non-partial) I aim to predict upcoming eclipses. The key idea here is to count the time (e.g. days) between consecutive eclipses and apply a ML-Algorithm on this pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dominik/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for converting dates to a JD-format, and back (not important for the presenation; you can skip this):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_to_jd(date):\n",
    "#transform date (either julian or gregorian) into a julian day number\n",
    "    y = date[0]\n",
    "    mo = date[1]\n",
    "    d = date[2]\n",
    "    h = date[3]\n",
    "    mn = date[4]\n",
    "    s = date[5]\n",
    "\n",
    "    if date[:3] >= [1582,10,15]:\n",
    "        #gregorian date\n",
    "        return 367*y - (7*(y+int((mo+9)/12)))//4 - (3*(int((y+(mo-9)/7)/100)+1))//4+(275*mo)//9+d+1721028.5+h/24+mn/(24*60)+s/86400\n",
    "    elif date[:3] <= [1582,10,4]:\n",
    "        #julian date\n",
    "        return 367*y - (7*(y+5001+int((mo-9)/7)))//4+(275*mo)//9+d+1729776.5+h/24+mn/(24*60)+s/86400\n",
    "\n",
    "def jd_to_date(jd):\n",
    "    Z = int(jd+0.5)\n",
    "    F = (jd+0.5)%1\n",
    "    if Z < 2299161:\n",
    "        A = Z\n",
    "    else:\n",
    "        g = int((Z - 1867216.25) / 36524.25)\n",
    "        A = Z + 1 + g - g//4 \n",
    "\n",
    "    B = A + 1524\n",
    "    C = int((B-122.1) / 365.25)\n",
    "    D = int(365.25 * C)\n",
    "    E = int((B-D) / 30.6001)\n",
    " \n",
    "    d = B - D - int(30.6001*E) + F\n",
    "    if E<14:\n",
    "        mo = E-1\n",
    "    else:\n",
    "        mo = E-13    \n",
    "\n",
    "    if mo >2:\n",
    "        y = C- 4716\n",
    "    else:\n",
    "        y = C - 4715\n",
    "    \n",
    "    return str(y)+'-'+mak_2_dig(mo)+'-'+mak_2_dig(int(d))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions for date-conversion (skip as well):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mak_2_dig(x):\n",
    "#transforms all integers bewteen 0 and 99 into a 2-digit string\n",
    "    if x<10:\n",
    "        return '0'+str(x)\n",
    "    else:\n",
    "        return str(x)\n",
    "\n",
    "\n",
    "def transf_date(s):\n",
    "    s = s.split()\n",
    "    s[1] = str(dic_months[s[1]])\n",
    "    return s[0]+':'+s[1]+':'+s[2]\n",
    "\n",
    "dic_months = {'January':1, 'February': 2, 'March':3, 'April':4, 'May':5, 'June': 6, 'July':7, 'August':8, 'September':9, 'October':10, 'November':11, 'December':12}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started. First, we read the data, drop unnecessary columns, and convert the times of eclipses to a JD-format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/solar.csv\")\n",
    "df = df.loc[:, ['Calendar Date', 'Eclipse Time', 'Eclipse Type']]\n",
    "#combine Date and Time to Time JD\n",
    "df['Calendar Date'] = df['Calendar Date'].apply(lambda x:transf_date(x))\n",
    "df['Time'] = df.loc[:,['Calendar Date', 'Eclipse Time']].apply(lambda x: x[0]+':'+x[1], axis = 1) \n",
    "df = df.drop(['Calendar Date', 'Eclipse Time'], axis=1)\n",
    "df['Time JD']=df['Time'].apply(lambda x : date_to_jd([int(j) for j in x.split(':')]))\n",
    "del df['Time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our modern worldview (we know about the earth moving around the sun, and the moon orbiting the earth), we know that the processes causing eclipses are periodic. Therefore, it might not be surprising to find visible patterns in the occurrence of eclipses. We here look at the time elapsing between consecutive eclipses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df['Eclipse Type'].str[0] != 'P']     #exclude partial eclipses\n",
    "##possibly exclude data prior to date\n",
    "#date_start = date_to_jd([1400, 1, 1, 0, 0, 0])   #only use data after this date\n",
    "#df = df[df['Time JD'] > date_start]\n",
    "t_between = df['Time JD'].diff().tolist()   #count days between consecutive eclipses\n",
    "t_between = t_between[1:-1]                 #drop first and last NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we check the durations beween eclipses for regularities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEKCAYAAADw2zkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJMNAkoRhIEnCMJAkYRhIkjAMJEnA/wMadv/vjfzrowAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8ab1f32588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(t_between,int(max(t_between))+1)\n",
    "plt.xlabel('Time (days)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is even better than expected - there are only very few possibilities of times between eclipses! Essentially only 6 (we ignore uncertainties of +-2 days):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{147, 148, 175, 176, 177, 178, 179, 324, 325, 354, 501, 502, 678, 679, 680}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([int(d) for d in t_between])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be worth noticing that the durations fulfill quite simple ratios: Based on l_0 = 147.5 days (the lowest of the times; almost never happening), we find that the ratios of the other durations and l_0 are roughly:\n",
    "\n",
    "6/5, 11/5, 12/5, 17/5, 23/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "\n",
    "I will compare some ML-Classifiers to predict the next eclipses. First, we specify 'today', which separates the data into learning and testing data, then we split the dates and times between accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "today = date_to_jd([2017, 3, 1, 0, 0,0])\n",
    "\n",
    "df_before = df[df['Time JD'] <= today]\n",
    "df_after = df[df['Time JD'] > today]\n",
    "dates_before = df_before['Time JD'].tolist()\n",
    "dates_after = df_after['Time JD'].tolist()\n",
    "diff_before = [int(j) for j in t_between[:len(dates_before)-1]]  #recorded differences between past ecl.\n",
    "diff_after =  [int(j) for j in t_between[len(dates_before)-1:]]   #differences betw. future ecl. to be predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The predictor should always predict the duration to the next eclipse from the past L eclipses. We specify this L (it is defined like this to make sure L is small enough that we can reasonably learn from the past), in fact I have optimized it through validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L = len(diff_before)//82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create the training set from diff_before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for j in range(len(diff_before)-L):\n",
    "    X.append(diff_before[j:j+L])\n",
    "    y.append(diff_before[j+L]) \n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform some kind of validation, I split the training data again - namely, I take the last fraction of size p of the training set for this (it doesn't make sense to randomly pick the validation set, since adjacent entries of X are highly correlated):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 0.15 #fraction used for validation\n",
    "X_val = X[int((1-p)*len(X)):]\n",
    "y_val = y[int((1-p)*len(y)):]\n",
    "\n",
    "X_train = X[:int((1-p)*len(X))]\n",
    "y_train = y[:int((1-p)*len(y))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick and train a learning algorithm on the (1-p)-training fraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=1000, n_jobs=1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lrn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(500,), learning_rate = 'adaptive')\n",
    "#lrn = SVC(kernel = 'linear', C=1000)     #just takes too long\n",
    "lrn = RandomForestClassifier(1000)\n",
    "lrn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test it on the validation set X_val (and accept deviations of +-1 days):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions more than 1 day off: 5.6%\n",
      "Tested on 916 samples\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "s = lrn.predict(X_val)\n",
    "for i in range(len(y_val)):\n",
    "    if np.absolute(y_val[i] - s[i]) > 1:\n",
    "        c += 1       #count wrong predictions\n",
    "print(\"Predictions more than 1 day off: {}%\".format(((c*1000)//len(y_val))/10))\n",
    "print(\"Tested on {} samples\".format(len(y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the three algorithms chosen above, the Random Forest Classifier produces the best results in a reasonable time, with an error rate greater than 5%.\n",
    "\n",
    "But I want to compare this result with a prediction model using XGBoost (optimizing the parameters is not shown here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions more than 1 day off: 3.6%\n",
      "Tested on 916 samples\n"
     ]
    }
   ],
   "source": [
    "lrn = xgb.XGBClassifier(learning_rate = 0.05, max_depth = 10, objective = \"reg:linear\")\n",
    "lrn.fit(X_train, y_train)\n",
    "\n",
    "c = 0\n",
    "s = lrn.predict(X_val)\n",
    "for i in range(len(y_val)):\n",
    "    if np.absolute(y_val[i] - s[i]) > 1:\n",
    "        c += 1       #count wrong predictions\n",
    "print(\"Predictions more than 1 day off: {}%\".format(((c*1000)//len(y_val))/10))\n",
    "print(\"Tested on {} samples\".format(len(y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great - XGBoost has an even lower error rate! We will stick to XGBoost for future predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having tested the quality of the prediction, we train the classifier again on the entire training set X, and then predict the next eclipses. Here, I will not only attempt to predict the next eclipse, but also some more eclipses ahead. Those further predictions will be based on the previous predictions, so errors are more likely to propagate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:       [176, 679, 176, 177, 176, 177, 176, 501, 177, 176]\n",
      "Calculated/true:  [176, 680, 176, 178, 176, 177, 176, 501, 177, 177]\n"
     ]
    }
   ],
   "source": [
    "N_future = 10   #number of predictions into the future\n",
    "lrn.fit(X, y)   # optionally train the model again on the 'entire' past \n",
    "#prediction part: append every further prediction to the feature set\n",
    "\n",
    "xx = np.array(X[-1])\n",
    "xx = np.roll(xx,-1)\n",
    "xx[-1] = y[-1]\n",
    "y_pred = []\n",
    "d_last = dates_before[-1]\n",
    "\n",
    "for i in range(N_future):\n",
    "    yy = lrn.predict([xx])\n",
    "    y_pred.append(yy[0])\n",
    "    xx = np.roll(xx,-1)\n",
    "    xx[-1] = yy\n",
    "\n",
    "\n",
    "print(\"Prediction:      \", y_pred)\n",
    "print(\"Calculated/true: \", diff_after[:N_future])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction is for the days between eclipses. In order to predict dates of eclipses, we compute the actual dates from this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date (predicted)   Date (calculated/true)\n",
      "  2017-08-21          2017-08-21\n",
      "  2019-07-01          2019-07-02\n",
      "  2019-12-24          2019-12-26\n",
      "  2020-06-18          2020-06-21\n",
      "  2020-12-11          2020-12-14\n",
      "  2021-06-06          2021-06-10\n",
      "  2021-11-29          2021-12-04\n",
      "  2023-04-14          2023-04-20\n",
      "  2023-10-08          2023-10-14\n",
      "  2024-04-01          2024-04-08\n"
     ]
    }
   ],
   "source": [
    "days_pred = [d_last + i for i in np.cumsum(y_pred)]\n",
    "print(\"Date (predicted)   Date (calculated/true)\")\n",
    "for i in range(len(days_pred)):\n",
    "    print(\"  \"+jd_to_date(days_pred[i])+\"          \"+jd_to_date(dates_after[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty good - in the case where we are not too unlucky, the predictions should be accurate up to a couple of days. Of course, once a single prediction is off, all further predictions are rendered worthless. But we need to keep in mind that this is how we have designed our model - to just predict the next eclipse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
